{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Model Development\n",
    "\n",
    "In this part, we develop three unique pipelines for predicting backorder. We use the smart sample from Part I to fit and evaluate these pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the smart sample here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reload your smart sampling from local file \n",
    "# ----------------------------------\n",
    "\n",
    "import joblib\n",
    "# Load the sampled data from the file\n",
    "dataset_new= joblib.load('dataset_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "197               0.0        2.0             0.0              54.0   \n",
       "606               0.0        2.0             0.0               2.0   \n",
       "846               1.0       12.0             0.0              18.0   \n",
       "882              -2.0        8.0             0.0              17.0   \n",
       "898               0.0        8.0             0.0              30.0   \n",
       "...               ...        ...             ...               ...   \n",
       "11897           105.0        8.0             0.0               0.0   \n",
       "1107399           2.0        8.0             0.0               0.0   \n",
       "652399            2.0        8.0             0.0               0.0   \n",
       "516580           21.0       16.0             0.0               0.0   \n",
       "1178875          72.0       16.0             0.0               0.0   \n",
       "\n",
       "         forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "197                  54.0              54.0            0.0            0.0   \n",
       "606                   2.0               2.0            3.0            3.0   \n",
       "846                  18.0              18.0            1.0            2.0   \n",
       "882                  23.0              33.0            2.0           12.0   \n",
       "898                  45.0              60.0           11.0           26.0   \n",
       "...                   ...               ...            ...            ...   \n",
       "11897                 0.0               0.0            3.0            6.0   \n",
       "1107399               0.0               0.0            0.0            0.0   \n",
       "652399                0.0               0.0            0.0            0.0   \n",
       "516580               20.0              20.0            5.0           13.0   \n",
       "1178875               0.0               0.0            0.0            3.0   \n",
       "\n",
       "         sales_6_month  sales_9_month  ...  pieces_past_due  perf_6_month_avg  \\\n",
       "197                0.0            0.0  ...              0.0              1.00   \n",
       "606                3.0            4.0  ...              0.0              0.73   \n",
       "846                8.0           15.0  ...              0.0              0.82   \n",
       "882               19.0           25.0  ...              0.0              0.37   \n",
       "898               42.0           73.0  ...              0.0              0.82   \n",
       "...                ...            ...  ...              ...               ...   \n",
       "11897              7.0            8.0  ...              0.0              1.00   \n",
       "1107399            0.0            0.0  ...              0.0              0.93   \n",
       "652399             0.0            0.0  ...              0.0              0.99   \n",
       "516580            49.0           74.0  ...              0.0              0.99   \n",
       "1178875            7.0            8.0  ...              0.0              0.62   \n",
       "\n",
       "         perf_12_month_avg  local_bo_qty  deck_risk  oe_constraint  ppap_risk  \\\n",
       "197                   0.98           0.0          1              0          1   \n",
       "606                   0.77           0.0          0              0          0   \n",
       "846                   0.79           0.0          0              0          0   \n",
       "882                   0.34           2.0          0              0          0   \n",
       "898                   0.81           0.0          0              0          0   \n",
       "...                    ...           ...        ...            ...        ...   \n",
       "11897                 0.94           0.0          0              0          0   \n",
       "1107399               0.91           0.0          0              0          0   \n",
       "652399                0.98           0.0          0              0          0   \n",
       "516580                0.94           0.0          0              0          0   \n",
       "1178875               0.62           0.0          0              0          0   \n",
       "\n",
       "         stop_auto_buy  rev_stop  went_on_backorder  \n",
       "197                  1         0                  1  \n",
       "606                  1         0                  1  \n",
       "846                  1         0                  1  \n",
       "882                  1         0                  1  \n",
       "898                  1         0                  1  \n",
       "...                ...       ...                ...  \n",
       "11897                1         0                  0  \n",
       "1107399              1         0                  0  \n",
       "652399               1         0                  0  \n",
       "516580               1         0                  0  \n",
       "1178875              1         0                  0  \n",
       "\n",
       "[22586 rows x 22 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_new.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize/standardize the data if required; otherwise ignore. You can perform this step inside the pipeline (if required). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_new.iloc [:, :-1]\n",
    "y = dataset_new.went_on_backorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Pipeline\n",
    "\n",
    "In this section, we design an operationalized machine learning pipeline, which includes:\n",
    "\n",
    "* Anomaly detection\n",
    "* Dimensionality Reduction\n",
    "* Train a classification model\n",
    "\n",
    "\n",
    "We are free to use any of the models that we learned in the past or we can use new models. Here is a pool of methods: \n",
    "\n",
    "### Pool of Anomaly Detection Methods (Discussed in M4)\n",
    "1. IsolationForest\n",
    "2. EllipticEnvelope\n",
    "3. LocalOutlierFactor\n",
    "4. OneClassSVM\n",
    "5. SGDOneClassSVM\n",
    "\n",
    "### Pool of Feature Selection Methods (Discussed in M3)\n",
    "\n",
    "1. VarianceThreshold\n",
    "1. SelectKBest with any scoring method (e.g, chi, f_classif, mutual_info_classif)\n",
    "1. SelectKPercentile\n",
    "3. SelectFpr, SelectFdr, or  SelectFwe\n",
    "1. GenericUnivariateSelect\n",
    "2. PCA\n",
    "3. Factor Analysis\n",
    "4. Variance Threshold\n",
    "5. RFE\n",
    "7. SelectFromModel\n",
    "\n",
    "\n",
    "### Classification Methods (Discussed in M1-M2\n",
    "1. Decision Tree\n",
    "2. Random Forest\n",
    "3. Logistic Regression\n",
    "4. Naive Bayes\n",
    "5. Linear SVC\n",
    "6. SVC with kernels\n",
    "7. KNeighborsClassifier\n",
    "8. GradientBoostingClassifier\n",
    "9. XGBClassifier\n",
    "10. LGBM Classifier\n",
    "\n",
    "\n",
    "\n",
    "It is difficult to fit an anomaly detection method in the sklearn pipeline without writing custom codes. For simplicity, we avoid fitting an anomaly detection method within a pipeline. So we can create the workflow in two steps. \n",
    "* Step I: fit an outlier with the training set\n",
    "* Step II: define a pipeline using a feature selection and a classification method. Then cross-validate this pipeline using the training data without outliers. \n",
    "* Note: if your smart sample is somewhat imbalanced, you might want to change the scoring method in GridSearchCV (see the [doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)).\n",
    "\n",
    "\n",
    "Once we fit the pipeline with gridsearch, we identify the best model and give an unbiased evaluation using the test set that we created in Part II. For unbiased evaluation we report confusion matrix, precision, recall, f1-score, accuracy, and other measures if you like. \n",
    "\n",
    "**Optional: Those who are interested in writing custom codes for adding an outlier detection method into the sklearn pipeline, please follow this discussion [thread](https://stackoverflow.com/questions/52346725/can-i-add-outlier-detection-and-removal-to-scikit-learn-pipeline).**\n",
    "\n",
    "\n",
    "**Note:** <span style='background:yellow'>We will be using Grid Search to find the optimal parameters of the pipelines.</span>\n",
    "\n",
    "You can add more notebook cells or import any Python modules as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 1st pipeline \n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation\n",
    "  \n",
    "Add cells as needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  -Anomaly detection: Isolation forest\n",
    "\n",
    "## -Dimensionality reduction: PCA\n",
    "\n",
    "\n",
    "## -Model training/validation : Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of outliers = 847\n"
     ]
    }
   ],
   "source": [
    "# Add anomaly detection code  (Question #E201)\n",
    "# ----------------------------------\n",
    "#Using IsolationForest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Constructing  IsolationForest\n",
    "iso_forest = IsolationForest(contamination=0.05).fit(X_train, y_train)\n",
    "\n",
    "# Get labels from classifier \n",
    "iso_out_pred= iso_forest.predict(X_train) == -1\n",
    "print(f\"Num of outliers = {np.sum(iso_out_pred)}\")\n",
    "iso_X_pred = X_train[~iso_out_pred]\n",
    "iso_y_pred = y_train[~iso_out_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E202)\n",
    "# ----------------------------------\n",
    "pipeline1 = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('PCA', PCA(n_components=20)),\n",
    "    ('LogisticRegression', LogisticRegression(max_iter=200))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and defining parameter grid for PCA and logistic regression\n",
    "    \n",
    "param_grid = {\n",
    "    'PCA__n_components': [20, 50, 100, 150, 200],\n",
    "    'LogisticRegression__solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "    'LogisticRegression__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'LogisticRegression__C':  [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.49985241\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.50002952        nan        nan        nan\n",
      "        nan 0.53362013        nan        nan        nan        nan\n",
      " 0.53367916        nan        nan        nan        nan 0.53362013\n",
      "        nan        nan        nan        nan 0.53362013        nan\n",
      "        nan        nan        nan 0.53362013        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.59796902        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.71344254        nan        nan        nan        nan\n",
      " 0.57583147        nan        nan        nan        nan 0.57335201\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.53302977        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.53308881        nan        nan        nan        nan 0.55203955\n",
      "        nan        nan        nan        nan 0.55203955        nan\n",
      "        nan        nan        nan 0.55203955        nan        nan\n",
      "        nan        nan 0.55203955        nan        nan        nan\n",
      "        nan 0.55203955        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.59796902        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.71344254\n",
      "        nan        nan        nan        nan 0.57583147        nan\n",
      "        nan        nan        nan 0.57335201        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.54678532        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.54460054        nan\n",
      "        nan        nan        nan 0.55351587        nan        nan\n",
      "        nan        nan 0.55357491        nan        nan        nan\n",
      "        nan 0.55339781        nan        nan        nan        nan\n",
      " 0.55416522        nan        nan        nan        nan 0.55363394\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.59796902\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.71344254        nan        nan\n",
      "        nan        nan 0.57577244        nan        nan        nan\n",
      "        nan 0.57329298        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.5676846\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.56756654        nan        nan        nan\n",
      "        nan 0.56189915        nan        nan        nan        nan\n",
      " 0.56189915        nan        nan        nan        nan 0.56189915\n",
      "        nan        nan        nan        nan 0.56178109        nan\n",
      "        nan        nan        nan 0.56189915        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.59796902        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.71344254        nan        nan        nan        nan\n",
      " 0.57577244        nan        nan        nan        nan 0.57329298\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.60481628        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.57276168        nan        nan        nan        nan 0.56803892\n",
      "        nan        nan        nan        nan 0.56797989        nan\n",
      "        nan        nan        nan 0.56797989        nan        nan\n",
      "        nan        nan 0.56792085        nan        nan        nan\n",
      "        nan 0.56792085        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.59796902        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.71344254\n",
      "        nan        nan        nan        nan 0.57577244        nan\n",
      "        nan        nan        nan 0.57341105        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.65375929        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.57335201        nan\n",
      "        nan        nan        nan 0.57429652        nan        nan\n",
      "        nan        nan 0.57447369        nan        nan        nan\n",
      "        nan 0.57447369        nan        nan        nan        nan\n",
      " 0.57352907        nan        nan        nan        nan 0.57264358\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.59796902\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.71344254        nan        nan\n",
      "        nan        nan 0.57577244        nan        nan        nan\n",
      "        nan 0.57341105        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.69850606\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.57335201        nan        nan        nan\n",
      "        nan 0.58244306        nan        nan        nan        nan\n",
      " 0.58445032        nan        nan        nan        nan 0.58450937\n",
      "        nan        nan        nan        nan 0.57559533        nan\n",
      "        nan        nan        nan 0.57329296        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.59796902        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.71344254        nan        nan        nan        nan\n",
      " 0.57583147        nan        nan        nan        nan 0.57341105\n",
      "        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('PCA', PCA(n_components=20)),\n",
       "                                       ('LogisticRegression',\n",
       "                                        LogisticRegression(max_iter=200))]),\n",
       "             n_jobs=2,\n",
       "             param_grid={'LogisticRegression__C': [0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                                                   1000],\n",
       "                         'LogisticRegression__penalty': ['l1', 'l2',\n",
       "                                                         'elasticnet', 'none'],\n",
       "                         'LogisticRegression__solver': ['lbfgs', 'liblinear',\n",
       "                                                        'newton-cg', 'sag',\n",
       "                                                        'saga'],\n",
       "                         'PCA__n_components': [20, 50, 100, 150, 200]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform grid search over the parameter grid\n",
    "model_grid_search = GridSearchCV(pipeline1, param_grid=param_grid, cv=5, n_jobs=2)\n",
    "model_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'LogisticRegression__C': 0.001, 'LogisticRegression__penalty': 'none', 'LogisticRegression__solver': 'newton-cg', 'PCA__n_components': 20}\n",
      "Best Score:  0.7134425362060437\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters and score from the grid search\n",
    "print('Best Parameters: ', model_grid_search.best_params_)\n",
    "print('Best Score: ', model_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making predictions on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using best pipeline to make predictions on the training data \n",
    "best_pipeline = model_grid_search.best_estimator_\n",
    "y_pred = best_pipeline.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Accuracy:  0.7129700690713737\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('Pipeline Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4890</td>\n",
       "      <td>3577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1285</td>\n",
       "      <td>7187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  4890  3577\n",
       "1  1285  7187"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given an unbiased evaluation \n",
    "#confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.58      0.67      8467\n",
      "           1       0.67      0.85      0.75      8472\n",
      "\n",
      "    accuracy                           0.71     16939\n",
      "   macro avg       0.73      0.71      0.71     16939\n",
      "weighted avg       0.73      0.71      0.71     16939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making predictions on testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t=best_pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Accuracy:  0.7154241190012396\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_t)\n",
    "print('Pipeline Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1678</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>459</td>\n",
       "      <td>2362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  1678  1148\n",
       "1   459  2362"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.59      0.68      2826\n",
      "           1       0.67      0.84      0.75      2821\n",
      "\n",
      "    accuracy                           0.72      5647\n",
      "   macro avg       0.73      0.72      0.71      5647\n",
      "weighted avg       0.73      0.72      0.71      5647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_test, y_pred_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E204)\n",
    "# ---------------------------------------------\n",
    "\n",
    "#hyperparameters\n",
    "PCA__n_components: The number of principle components to preserve after PCA is known as PCA__n_components. There is a list of potential values for this parameter in the grid, with a range of 20 to 200 and a step of 50.\n",
    "\n",
    "LogisticRegression__solver: The logistic regression optimization problem is solved using the logisticRegression__solver algorithm. A list of potential solutions, including 'lbfgs', 'liblinear', 'newton-cg','sag', and'saga', is included in the grid.\n",
    "\n",
    "LogisticRegression__penalty: TThe regularization technique to be used in logistic regression is specified by the parameter logisticRegression__penalty. 'l1', 'l2', 'elasticnet', and 'none' are among the list of potential penalties that can be applied to the grid.\n",
    "\n",
    "LogisticRegression__C: The inverse of regularization strength is a logistic regression, or logistic regression__C. Stronger regularization is specified by smaller values of C. There is a list of C's potential values on the grid including 0.001, 0.01, 0.1, 1, 10, 100, 1000.\n",
    "\n",
    "\n",
    "Results:\n",
    "-For outlier detection, I've used Isolation forest and can see that there are 847 outliers.\n",
    "-The best parameters are 'LogisticRegression__C': 0.001, 'LogisticRegression__penalty': 'none', 'LogisticRegression__solver': 'newton-cg', 'PCA__n_components': 20 with a score of 71%.\n",
    "\n",
    "\n",
    "-And The pipeline accuracy came up to be 71% when used on training data and 72% while predicting against testing data.\n",
    "\n",
    "\n",
    "-The result of confusion matrix while predicting on testing data:-\n",
    "There are 4890 samples that belong to class 0 and were correctly classified as class 0 (true negatives).\n",
    "There are 3577 samples that belong to class 1 but were incorrectly classified as class 0 (false negatives).\n",
    "There are 1285 samples that belong to class 0 but were incorrectly classified as class 1 (false positives).\n",
    "There are 7187 samples that belong to class 1 and were correctly classified as class 1 (true positives).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- The result of confusion matrix while predicting on testing data :-\n",
    "True Positive = 2362: The model correctly predicted 2362 samples as positive (class 1) out of the total 2362 actual positive samples.\n",
    "False Positive = 1148: The model incorrectly predicted 1148 samples as positive (class 1) when they were actually negative (class 0).\n",
    "False Negative = 459: The model incorrectly predicted 459 samples as negative (class 0) when they were actually positive (class 1).\n",
    "True Negative = 1678: The model correctly predicted 1678 samples as negative (class 0) out of the total 1678 actual negative samples.\n",
    "\n",
    "-Result of classification report while testing on training data :\n",
    "The classifier classified 71% of the samples correctly, resulting in an overall accuracy of 0.71. The classifier performed better at detecting positive samples as evidenced by the fact that class 1 had greater precision, recall, and F1 scores than class 0 did. The classifier, however, tends to predict false positives for class 0 because its precision was rather low. A useful general indicator of performance is the F1 score, which is higher for class 1 than for class 0.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-Result of classification report while testing on testing data :-\n",
    "The model's total accuracy while on training data was 0.71, meaning that 71% of the cases had their class properly predicted. The model accurately recognized 79% of the examples that belong to class 0, but it also correctly predicted 41% of the instances that belong to class 1. The precision and recall for class 0 are 0.79 and 0.59, respectively. The model accurately recognized 84% of the cases that belong to class 1, but it also correctly predicted 33% of the instances that belong to class 0 as class 1. The precision and recall for class 1 are 0.67 and 0.84, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 2nd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  -Anomaly detection: Elliptic envelope\n",
    "\n",
    "## -Dimensionality reduction: FA\n",
    "\n",
    "## -Model training/validation : SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EllipticEnvelope(contamination=0.05)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add anomaly detection code  (Question #E205)\n",
    "# ----------------------------------\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "model_ee = EllipticEnvelope(contamination=0.05) # adjust the contamination level as needed\n",
    "model_ee.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the anomalies\n",
    "y_pred_out = model_ee.predict(X)\n",
    "anomalies = X[y_pred_out == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies: 1130\n",
      "Anomalies:          national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
      "2256            356.0        8.0           279.0            7419.0   \n",
      "5808              0.0        8.0             0.0               0.0   \n",
      "6602             17.0        8.0             0.0              75.0   \n",
      "8579             31.0        8.0             1.0            1265.0   \n",
      "8755            -13.0        8.0            53.0             599.0   \n",
      "...               ...        ...             ...               ...   \n",
      "1113189         837.0        2.0          1401.0            1754.0   \n",
      "1319984          34.0        8.0             0.0               0.0   \n",
      "1024431        1533.0        2.0             0.0               0.0   \n",
      "1097205       12668.0        4.0          6010.0           15000.0   \n",
      "51001           309.0       52.0             0.0               0.0   \n",
      "\n",
      "         forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
      "2256               7419.0            9405.0          808.0         2611.0   \n",
      "5808                  0.0               0.0           26.0          155.0   \n",
      "6602                111.0             147.0           10.0           36.0   \n",
      "8579               1745.0            2065.0          209.0          602.0   \n",
      "8755                599.0             731.0          153.0          719.0   \n",
      "...                   ...               ...            ...            ...   \n",
      "1113189            3185.0            4475.0          876.0         1679.0   \n",
      "1319984               0.0               0.0           67.0          192.0   \n",
      "1024431               0.0               0.0            8.0         1727.0   \n",
      "1097205           35000.0           50000.0         4514.0        15772.0   \n",
      "51001                 0.0               0.0            9.0           18.0   \n",
      "\n",
      "         sales_6_month  sales_9_month  ...  potential_issue  pieces_past_due  \\\n",
      "2256            5828.0         9664.0  ...                0            600.0   \n",
      "5808             199.0          286.0  ...                0              0.0   \n",
      "6602              85.0          132.0  ...                0              0.0   \n",
      "8579            1323.0         2371.0  ...                0             48.0   \n",
      "8755            1068.0        11371.0  ...                0              0.0   \n",
      "...                ...            ...  ...              ...              ...   \n",
      "1113189         3151.0         5320.0  ...                0              0.0   \n",
      "1319984          367.0          589.0  ...                0              0.0   \n",
      "1024431         2119.0         2347.0  ...                0              0.0   \n",
      "1097205        30575.0        47655.0  ...                0              0.0   \n",
      "51001             21.0           30.0  ...                0              0.0   \n",
      "\n",
      "         perf_6_month_avg  perf_12_month_avg  local_bo_qty  deck_risk  \\\n",
      "2256                 0.52               0.53          13.0          0   \n",
      "5808               -99.00             -99.00           0.0          1   \n",
      "6602               -99.00             -99.00           0.0          0   \n",
      "8579                 0.57               0.48          13.0          0   \n",
      "8755                 0.30               0.32          25.0          0   \n",
      "...                   ...                ...           ...        ...   \n",
      "1113189              1.00               0.98           0.0          0   \n",
      "1319984            -99.00             -99.00           0.0          1   \n",
      "1024431              0.68               0.79           0.0          0   \n",
      "1097205              0.98               0.96           0.0          0   \n",
      "51001              -99.00             -99.00           0.0          1   \n",
      "\n",
      "         oe_constraint  ppap_risk  stop_auto_buy  rev_stop  \n",
      "2256                 0          0              1         0  \n",
      "5808                 0          0              1         0  \n",
      "6602                 0          0              1         0  \n",
      "8579                 0          0              1         0  \n",
      "8755                 0          1              1         0  \n",
      "...                ...        ...            ...       ...  \n",
      "1113189              0          0              1         0  \n",
      "1319984              0          0              1         0  \n",
      "1024431              0          0              1         0  \n",
      "1097205              0          0              1         0  \n",
      "51001                0          0              1         0  \n",
      "\n",
      "[1130 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print('Number of anomalies:', len(anomalies))\n",
    "print('Anomalies:', anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E206)\n",
    "# ----------------------------------\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform\n",
    "from sklearn.decomposition import FactorAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline2 = Pipeline([\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('FA', FactorAnalysis(n_components=20)),\n",
    "    ('SVC', SVC(kernel='rbf'))\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "     'FA__n_components': [5, 10, 15],\n",
    "    'SVC__C': [1e3, 5e3],        \n",
    "    'SVC__kernel': ['rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scale', MinMaxScaler()),\n",
       "                                       ('FA', FactorAnalysis(n_components=20)),\n",
       "                                       ('SVC', SVC())]),\n",
       "             n_jobs=2,\n",
       "             param_grid={'FA__n_components': [5, 10, 15],\n",
       "                         'SVC__C': [1000.0, 5000.0], 'SVC__kernel': ['rbf']})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform grid search\n",
    "model_grid_search2 = GridSearchCV(pipeline2, param_grid=param_grid, cv=5,n_jobs=2)\n",
    "model_grid_search2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'FA__n_components': 15, 'SVC__C': 5000.0, 'SVC__kernel': 'rbf'}\n",
      "Best Score:  0.7433140778216872\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters and score from the grid search\n",
    "print('Best Parameters: ', model_grid_search2.best_params_)\n",
    "print('Best Score: ', model_grid_search2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making predictions on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using best pipeline to make predictions on the test data\n",
    "best_pipeline = model_grid_search2.best_estimator_\n",
    "y_pred2 = best_pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Accuracy:  0.7507527008678199\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_train, y_pred2)\n",
    "print('Pipeline Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6580</td>\n",
       "      <td>1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2335</td>\n",
       "      <td>6137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  6580  1887\n",
       "1  2335  6137"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E207)\n",
    "# ----------------------------------\n",
    "#confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      8467\n",
      "           1       0.76      0.72      0.74      8472\n",
      "\n",
      "    accuracy                           0.75     16939\n",
      "   macro avg       0.75      0.75      0.75     16939\n",
      "weighted avg       0.75      0.75      0.75     16939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making predictions on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2_t = best_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Accuracy:  0.737559766247565\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred2_t)\n",
    "print('Pipeline Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2164</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>820</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2164   662\n",
       "1   820  2001"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred2_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74      2826\n",
      "           1       0.75      0.71      0.73      2821\n",
      "\n",
      "    accuracy                           0.74      5647\n",
      "   macro avg       0.74      0.74      0.74      5647\n",
      "weighted avg       0.74      0.74      0.74      5647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_test, y_pred2_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E208)\n",
    "# ---------------------------------------------\n",
    "\n",
    "#Hyperparameters:-\n",
    "FA__n_components': The number of components to retain following the dimensionality reduction stage using Factor Analysis is specified by FA__n_components': [5, 10, 15].\n",
    "The SVM classifier's regularization parameter C is defined by the expression \"SVC__C\": [1e3, 5e3]. A narrower margin and a more complicated decision border are produced by a higher C value, whereas a broader margin and a simpler choice boundary are produced by a smaller C value.\n",
    "The kernel function to be used for the SVM classifier is specified by the 'SVC__kernel': ['rbf'] variable. It is the radial basis function (RBF) kernel in this instance, which is frequently employed for non-linear classification applications.\n",
    "\n",
    "Results:\n",
    "- For finding number of outliers, I've used Elliptic envelope, and found out to have 1130 anamolies.\n",
    "- The best parameters are 'FA__n_components': 15, 'SVC__C': 5000.0, 'SVC__kernel': 'rbf' and score I got was 74%.\n",
    "- The pipeline accuracy score is 75% using training data and 73% using testing data.\n",
    "\n",
    "- The result of confusion matrix on training data:-\n",
    "The classifier predicted the two primary diagonal elements of the matrix, 6580 true negatives and 6137 true positives. Although it also predicted 1887 false positives (samples that were actually negative but were projected as positive) and 2335 false negatives (samples that were actually positive but were forecasted as negative), these predictions were less accurate.\n",
    "\n",
    "\n",
    "- The result of confusion matrix on testing data:-\n",
    "In your confusion matrix, there are 2164 true negatives (TN), 662 false positives (FP), 820 false negatives (FN), and 2001 true positives (TP).\n",
    "\n",
    "\n",
    "\n",
    "-The result of classification report on testing data:-\n",
    "\n",
    "The classification model achieved an overall accuracy of 0.75, with a precision of 0.74 and recall of 0.78 for the \"0\" class, and a precision of 0.76 and recall of 0.72 for the \"1\" class, resulting in an F1-score of 0.76 for class \"0\" and 0.74 for class \"1\".\n",
    "\n",
    "\n",
    "\n",
    "-The result of classification report on testing data:-\n",
    "The model's accuracy is 0.74, which indicates that it correctly identified the sample's class in 74% of cases. Precision, recall, and F1-score's macro average is also 0.74, demonstrating balanced performance in both classes. For class 0, the recall is 0.77, which means that the model correctly identifies 77% of the samples that belong to class 0. For class 1, the recall is 0.71, which means that the model correctly identifies 71% of the samples that belong to class 1.Precision, recall, and F1-score have a weighted average of 0.74, which indicates that they are affected by the quantity of samples in each class and are greater for the class with more samples.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 3rd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  -Anomaly detection: LocalOutlierFactor\n",
    "\n",
    "## -Dimensionality reduction: RFE\n",
    "\n",
    "\n",
    "## -Model training/validation : Random forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add anomaly detection code  (Question #E209)\n",
    "# ----------------------------------\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and make predictions\n",
    "y_pred_out = lof.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of outliers detected\n",
    "n_outliers = np.sum(y_pred_out == -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers detected:  2256\n"
     ]
    }
   ],
   "source": [
    "# Print the number of outliers detected\n",
    "print(\"Number of outliers detected: \", n_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E210)\n",
    "# ----------------------------------\n",
    "#pipelining with RFE as feature selector and random forest for classification\n",
    "pipeline3 = Pipeline([\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('rfe', RFE(estimator=RandomForestClassifier())),\n",
    "    ('rf', RandomForestClassifier())\n",
    "\n",
    "])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'rfe__n_features_to_select': [5, 10, 15],\n",
    "    'rf__n_estimators': [100, 200, 500],\n",
    "    'rf__max_depth': [5, 10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scale', MinMaxScaler()),\n",
       "                                       ('rfe',\n",
       "                                        RFE(estimator=RandomForestClassifier())),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=5,\n",
       "             param_grid={'rf__max_depth': [5, 10, 20],\n",
       "                         'rf__n_estimators': [100, 200, 500],\n",
       "                         'rfe__n_features_to_select': [5, 10, 15]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training by Performining grid search\n",
    "model_grid_search3 = GridSearchCV(pipeline3, param_grid=param_grid, cv=10,n_jobs=5)\n",
    "model_grid_search3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'rf__max_depth': 20, 'rf__n_estimators': 200, 'rfe__n_features_to_select': 15}\n",
      "Best Score:  0.9007617657539797\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters and score from the grid search\n",
    "print('Best Parameters: ', model_grid_search3.best_params_)\n",
    "print('Best Score: ', model_grid_search3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making predictions on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using best pipeline to make predictions on the training data\n",
    "best_pipeline3 = model_grid_search3.best_estimator_\n",
    "y_pred3 = best_pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Accuracy:  0.9757955015054017\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred3)\n",
    "print('Pipeline Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8143</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>8386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  8143   324\n",
       "1    86  8386"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E211)\n",
    "# ----------------------------------\n",
    "#confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      8467\n",
      "           1       0.96      0.99      0.98      8472\n",
      "\n",
      "    accuracy                           0.98     16939\n",
      "   macro avg       0.98      0.98      0.98     16939\n",
      "weighted avg       0.98      0.98      0.98     16939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_train, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making predictions on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3_t = best_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Accuracy:  0.9015406410483443\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred3_t)\n",
    "print('Pipeline Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2462</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2462   364\n",
       "1   192  2629"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred3_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90      2826\n",
      "           1       0.88      0.93      0.90      2821\n",
      "\n",
      "    accuracy                           0.90      5647\n",
      "   macro avg       0.90      0.90      0.90      5647\n",
      "weighted avg       0.90      0.90      0.90      5647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_test, y_pred3_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E212)\n",
    "# -------------------------------------------\n",
    "\n",
    "#Hyperparameters:-\n",
    "rfe__n_features_to_select: This option determines how many features the RFE algorithm will choose from. The values 5, 10, and 15 will be used in the grid search to fine-tune this parameter.\n",
    "\n",
    "rf__n_estimators: The number of trees in the RF ensemble is specified by this parameter. This parameter will be tuned using the values 100, 200, and 500 in the grid search.\n",
    "\n",
    "Rf__max_depth: The maximum depth of each tree in the RF ensemble is specified by this parameter. This parameter will be tuned using the values 5, 10, and 20 in the grid search.\n",
    "\n",
    "Results:\n",
    "- for finding no.of outliers I've used Local outlier factor and achieved 2256 outliers present.\n",
    "- The Best parameters are 'rf__max_depth': 20, 'rf__n_estimators': 500, 'rfe__n_features_to_select': 15 with a score of 90%\n",
    "- The accuracy of the pipeline is 97% using on testing data and 90% while using testing data\n",
    "\n",
    "- Result of confusion Matrix on training data:-\n",
    "\n",
    "The model correctly identified 8388 instances as class 1 and 8158 instances as class 0. However, it misclassified 309 instances as class 1 when they were actually class 0 and 84 instances as class 0 when they were actually class 1.\n",
    "\n",
    "\n",
    "- Result of confusion Matrix on training data:-\n",
    "For class 0, the precision is 0.99, meaning that 99% of the examples that the model predicted to be in class 0 are in fact in class 0. Recall for class 0 is 0.96, which indicates that 96% of all actual class 0 occurrences were correctly identified by the model. The harmonic mean of precision and recall for class 0 is represented by the f1-score, which is 0.98 for class 0. The number of actual instances of class 0 in the dataset, or the support for class 0, is 8467. The weighted average and macro average are reported for all classes combined, and the same metrics are reported for class 1.  The model's overall accuracy is 0.98.\n",
    "\n",
    "\n",
    "\n",
    "- Result of confusion Matrix on testing data:-\n",
    "\n",
    "There were 2639 true positives (occurrences that were actually positive and were correctly classified as positive), 359 false positives (occurrences that were actually positive but were incorrectly classified as negative), and 2467 true negatives (occurrences that were actually negative and were correctly classified as negative) in this confusion matrix.\n",
    "\n",
    "-Result of classification report on testing data:-\n",
    "In this study, the model's accuracy was 0.90, meaning that 90% of the cases in the dataset had their class accurately predicted. The precision for class 0 is 0.93, which indicates that 93% of the time the model is right when it predicts that a sample belongs to class 0. Recall for class 0 is 0.87, which indicates that 87% of actual samples are correctly identified as being in class 0 by the model. The harmonic mean of recall and precision yields the F1-score for class 0 at 0.90.\n",
    "\n",
    "The precision for class 1 is also 0.88, meaning that 88% of the time the model is right when it predicts that a sample belongs to class 1. The model accurately identifies 94% of the actual samples as being in class 1 according to the recall for class 1, which is 0.94. The harmonic mean of recall and precision yields an F1-score for class 1 of 0.91. The model does well in both classes, as evidenced by the macro-average of precision, recall, and F1-score, which is 0.91.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare these three pipelines and discuss your findings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your analysis in this cell (Question #E213)\n",
    "# ----------------------------------\n",
    "\n",
    "Already discussed individually the results of each after running each model where,\n",
    "\n",
    "Pipeline-1: Model's pipeline accuracy is 71% while using predicting on testing data and 72% while using on training data.\n",
    "According to classification report, the accuracy of the model is 71% while testing on both training and testing data.\n",
    "\n",
    "Pipeline-2: Model's pipeline accuracy is 75% while testing it on training data and 73% while testing it on testing data.\n",
    "According to the classification report the model accuracy is 75% when predicted on training data and 74% while testing it on the testing data.\n",
    "\n",
    "\n",
    "pipeline-3: Model's pipeline accuracy is 97% while testing it on training data and 90% while using it on testing data.\n",
    "According to the classification report, the model accuracy is 98% when predicted on training data and 90% while being trained on testing data.\n",
    "\n",
    "So from above we can see the combination of taking RFE as a feature selector and random forest as a classifier works best by giving an accuracy of 98% which is more than other combinations that I've tried.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the required pipeline/models for Part III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model1.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "joblib.dump(model_grid_search, 'model1.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline2.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_grid_search2, 'pipeline2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bestmodel.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model_grid_search3,'bestmodel.pkl')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have made a few commits so far of this project.  \n",
    "**Definitely make a commit of the notebook now!**  \n",
    "Comment should be: `Final Project, Checkpoint - Pipelines done`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!\n",
    "## Then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
